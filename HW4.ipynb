{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlK2M0CRbmrb"
   },
   "source": [
    "# HW 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfCMNRQdbmrd"
   },
   "source": [
    "## Instructions\n",
    "\n",
    "* The course will be using an automatic grading system.\n",
    "* After each question there will appear a code block with some prepared code to add your answer to a dictionary that will be converted into a data frame, saved as CSV and uploaded to moodle for grading.\n",
    "* Please do not edit any code other than in placeholders marked `#### your code here ####`, **notice the answer could also be a simple number or string, not an actual code**\n",
    "* Don't forget to run the code block after you write your answer.\n",
    "* You can add code blocks wherever you want in order to interact with datasets and play with your own code.\n",
    "* In the next code block please fill in your ID number and email account as strings in the appropriate places.\n",
    "* And don't forget to run the block!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shmbfA9ibmre"
   },
   "outputs": [],
   "source": [
    "ans = {}\n",
    "ans['HW'] = 'HW4'\n",
    "ans['id_number'] = #### your code here ####\n",
    "ans['email'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZPZF5kCKZKs"
   },
   "source": [
    "### Q1.\n",
    "$\\mathbf{z}\\in \\mathbb R^n$ is a vector with norm $1$ and average $0$, and we create a matrix $X_{n*3}$ by making the first and second columns equal to $\\mathbf{z}$, and the third column equal to $-\\mathbf{z}$. Which of the following can be the direction $\\mathbf{v}_1$ of the first principal component?\n",
    "\n",
    "1. $(1,1,-1)$\n",
    "2. $(1/\\sqrt{3},1/\\sqrt{3},1/\\sqrt{3})$\n",
    "3. $(1/\\sqrt{3},1/\\sqrt{3},-1/\\sqrt{3})$\n",
    "4. There is not enough information to know\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyJyR796iZbe"
   },
   "outputs": [],
   "source": [
    "ans['Q1'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVPxiwf2p4d6"
   },
   "source": [
    "### Q2.\n",
    "With the same settings as Q1, how much of the variance is explained by the second principal component? \n",
    "\n",
    "1. $1$\n",
    "2. $1/\\sqrt(3)$\n",
    "3. Practically $0$\n",
    "4. There is not enough information to know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UToX1CdotP1l"
   },
   "outputs": [],
   "source": [
    "ans['Q2'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pegveoh1iZbg"
   },
   "source": [
    "### Q3.\n",
    "\n",
    "Assume that I do a PCA of a movie reviews matrix like the one we did in class, and I get that the first principal direction $\\mathbf{v}_1$ has all equal positive loadings (i.e., it is the average of the data), and the second principal direction $\\mathbf{v}_2$ has positive loadings for comedy and negative for action movies (i.e., it separates action lovers from comedy lovers). This is similar to what we got on the actual data. Now assume also that when I plot all observations in the two dimensional space I get by projecting them on the first two PCs (as we did in class), I get two distinct clusters, one high on both coordinates, and one low on both (this is not as we got in class). What can be said about the nature of my reviews data?\n",
    "\n",
    "1. Comedy lovers tend to give higher reviews overall than action lovers\n",
    "2. There are more comedies than action movies in my data\n",
    "3. The comedies get higher reviews than action movies\n",
    "4. None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ychWSrDhiZbh"
   },
   "outputs": [],
   "source": [
    "ans['Q3'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HE_Dl9sDiZbj"
   },
   "source": [
    "### Q4.\n",
    "\n",
    "Given a centered matrix $X_{n \\times p}$ and its first principal component direction $\\mathbf{v}_1$, the first principal projection is $X \\mathbf{v}_1 \\in \\mathbb R^n$. Denote this vector by $\\mathbf{r}_1$. What is the connection between $\\mathbf{r}_1$ and the first singular value $\\lambda_1$ form the SVD of $X$?\n",
    "\n",
    "1.       $\\|\\mathbf{r}_1\\|^2_2 = \\lambda_1$\n",
    "2.       $\\|\\mathbf{r}_1\\|^2_2 = \\lambda_1^2$\n",
    "3.       $\\mathbf{v}_1 \\cdot \\lambda_1 = \\mathbf{r}_1 $\n",
    "4.       There is no connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qfc8lXviZbj"
   },
   "outputs": [],
   "source": [
    "ans['Q4'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSpNkE6oiZbm"
   },
   "source": [
    "## Probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHMk6PMnLEQl"
   },
   "source": [
    "### Q5.\n",
    "\n",
    "It has been found that in a typical Researcher's academic life span, the number of experiments she would run is 100, with the probability of \"reaching the wrong conclusion\" of 0.01. What is the expected number of experiments \"reaching the wrong conclusion\" in a typical Researcher's academic life, and what is the probability that a typical Researcher would \"reach the wrong conclusion\" in at least 1 experiment during her academic life?\n",
    "\n",
    "1. 1 and 1, respectively\n",
    "2. 1 and 0.63, respectively\n",
    "3. 10 and 0.63, respectiverly\n",
    "4. 10 and 0.99, respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4f_JwzkiZbm"
   },
   "outputs": [],
   "source": [
    "ans['Q5'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ItcB1SniZbp"
   },
   "source": [
    "### Q6.\n",
    "\n",
    "A Web Analyst has tested 3 different versions of a website, each seen by a different amount of users. For each version, for each user, the Analyst knows whether the user has signed up for the website or not. He puts the results in a contingency table:\n",
    "\n",
    "|  Version/Sign | Yes  | No|\n",
    "|-----|--------|---------|\n",
    "| V1   |   1000    |   3000     |\n",
    "| V2   |   400    |   100  |\n",
    "| V3   |   900 |   2700  |\n",
    "\n",
    "What is the probability a user seeing V2 will not sign up to the website?\n",
    "\n",
    "1. 0.20\n",
    "2. 0.25\n",
    "3. 0.33\n",
    "4. 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKGDEaBziZbp"
   },
   "outputs": [],
   "source": [
    "ans['Q6'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yn43Mxm9iZbs"
   },
   "source": [
    "### Q7.\n",
    "\n",
    "Which of the following is correct?\n",
    "\n",
    "1. A user signing up to the website is 2.5 more likely to have seen V3 of the website, than V2.\n",
    "2. A user who has seen V1 is 2.5 more likely to sign up to the website, than a user who has seen V2.\n",
    "3. A user who has seen V2 is 3.2 more likely to sign up to the website, than a user who has seen V1.\n",
    "4. A user not signing up to the website has 10% more chance to have seen V1, than V3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPIxwDf-iZbs"
   },
   "outputs": [],
   "source": [
    "ans['Q7'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UdcWuxzxbq7"
   },
   "source": [
    "### Q8.\n",
    "\n",
    "Based on the following data which airlines preforms better? (Delay rate is the percent of delays from scheduled departures, an airline company would want to minimize this metric, nothing tricky)\n",
    "\n",
    "\n",
    "|  | Airlines A | | Airlines B |  |\n",
    "|---|----|----|----|----|\n",
    "| City | # flights | Delay rate (%) | # flights| Delay rate (%) |\n",
    "|---|----|----|----|----|\n",
    "| Los Angeles |559 |11.1  |811| 14.4|\n",
    "| Phoenix |233 | 5.2 |5255| 7.9|\n",
    "| San Deigo |232 | 8.6 |448| 14.5|\n",
    "| San Fransisco | 605 | 16.9 | 449 | 28.7|\n",
    "| Seattle |2146 | 14.2 |262| 23.3|\n",
    "| __TOTAL__ | __3775__ | __13.3__| __7225__ | __11.0__|\n",
    "\n",
    "\n",
    "1. Airlines A preforms better\n",
    "\n",
    "2. Airlines B preforms better\n",
    "\n",
    "3. The results are inconclusive\n",
    "\n",
    "4. We cannot compare between the airlines since the number of flights is dramatically different. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmT9Oc9OheLw"
   },
   "outputs": [],
   "source": [
    "ans['Q8'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCHqgMiOiZbv"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJKvN9_-zW9I"
   },
   "source": [
    "### Q9.\n",
    "\n",
    "According to the attacthed script:\n",
    "```python\n",
    "import seaborn as sns\n",
    "\n",
    "sns.relplot(x=\"horsepower\", y=\"mpg\", hue=\"origin\", size=\"weight\",\n",
    "            sizes=(40, 400), alpha=.5, palette=\"muted\",\n",
    "            height=6, data=mpg)\n",
    "```\n",
    "Which of the following is correct?\n",
    "\n",
    "1. This is a 3d plot (x-axis = \"horsepower\", y-axis = \"mpg\", z-axis = \"weight\")\n",
    "\n",
    "2. Given that the origin variable has only 3 unique values, the dots on the plot will be composed of 3 colors.\n",
    "\n",
    "3. Given that the origin variable has only 3 unique values, the figure will be composed of 3 plots (side-by-side).\n",
    "\n",
    "4. The size of each dot on the  plot is either  40 or 400 (unrelated to the weight variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yfq_uL9jNdgX"
   },
   "outputs": [],
   "source": [
    "ans['Q9'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt52-YByrYzM"
   },
   "source": [
    "### Q10.\n",
    "\n",
    "Fill in the missing line to produce two boxplots of `y`, side by side, one for each value of `x`:\n",
    "\n",
    "```python\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    sns.set()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'x': np.concatenate([np.tile('a', 100), np.tile('b', 100)]),\n",
    "        'y': np.concatenate([np.random.normal(size = 100), np.random.exponential(size = 100)])}\n",
    "    )\n",
    "\n",
    "    # missing line 1 #\n",
    "```\n",
    "\n",
    "   1. `sns.boxplot(x=df.x, y=df.y)`\n",
    "   2. `sns.boxplot(x=df['x'], y=df['y'])`\n",
    "   3. `sns.boxplot(df, x='x', y='y'))`\n",
    "   4. All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTh-YV55iZb4"
   },
   "outputs": [],
   "source": [
    "ans['Q10'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on ebay images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention!! Questions 11-15 are about the ebay images dataset we scraped on HW2. If you have the images on your local machine or GD, you don't need to re-unzip them.**\n",
    "\n",
    "**Also! The real value is in the little analysis coming just before them, put your focus on that.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ebay_boys_girls_shirts.tar.gz` file is about 250MB on disk. You can either:\n",
    "\n",
    "1. Store it on your local machine, read and extract it as shown below (because you're working with Jupyter Notebooks). Notice this would extract all images locally, you would not have to do this again later on.\n",
    "2. Store it on your local machine, then **if you have a super-fast internet connection** upload it manually to your Google Colab notebook environment like any other file, exrtact it there -- the upload might be very slow, so not recommended\n",
    "3. Store it on Google Drive, then ount Google Drive, copy the file to your Google Colab notebook, then extract it there -- my preferred option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run just one of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option 1\n",
    "# import tarfile\n",
    "\n",
    "# path = '../' # this is the path to my local file, what is yours?\n",
    "\n",
    "# # extract it\n",
    "# with tarfile.open(path + 'ebay_boys_girls_shirts.tar.gz') as tar:\n",
    "#     tar.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option 2\n",
    "# # (after you have uploaded the file to Google Colab notebook - really, it didn't take hours?!)\n",
    "# !tar -xzvf ebay_boys_girls_shirts.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option 3\n",
    "# # copy the file from GD\n",
    "# !cp drive/MyDrive/ebay_boys_girls_shirts.tar.gz .\n",
    "\n",
    "# # extract it\n",
    "# !tar -xzvf ebay_boys_girls_shirts.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the images, let's look at some of the images in the training set. In order to see boys vs. girls shirts, we'll display a random group from each folder, side by side.\n",
    "\n",
    "Let's get the metadata CSV files first as `pandas` DataFrames. Inspect these DF's and understand what the data in them means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = '../' # this is MY path, e.g. if the folder is in the current notebook environment, change this to '.'\n",
    "folder = path + 'ebay_boys_girls_shirts/'\n",
    "boys_train_df = pd.read_csv(folder + 'boys_train.csv')\n",
    "girls_train_df = pd.read_csv(folder + 'girls_train.csv')\n",
    "\n",
    "boys_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gil5O1kCHEtM"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform, color, img_as_ubyte\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_file_list(df, folder, n_sample = None, seed = None):\n",
    "    if n_sample is None:\n",
    "        file_ids_list = df.file_id.values\n",
    "    else:\n",
    "        file_ids_list = df.sample(n = n_sample, random_state = seed).file_id.values\n",
    "    files_list = [folder + '/' + str(file_id) + '.jpg' for file_id in file_ids_list]\n",
    "    return files_list\n",
    "\n",
    "def read_image_and_resize(f, w = 100, h = 100):\n",
    "    if f.endswith('jpg'):\n",
    "        img = cv2.imread(f)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            img = transform.resize(img, (w, h), mode='constant') \n",
    "            img = img_as_ubyte(img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img[np.newaxis, :, :, :3]\n",
    "        if img.shape != (1, 100, 100, 3):\n",
    "            raise ValueError(f + str(img.shape))\n",
    "    return img\n",
    "\n",
    "def read_images_4d_array(files_list):\n",
    "    images_list = [read_image_and_resize(file) for file in files_list]\n",
    "    images_array = np.concatenate(images_list)\n",
    "    return images_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vsv2J8-xHEtP"
   },
   "source": [
    "Complete the `get_images_matrix` function **using the above functions** to unite what we did into a single function receiving `csv_file` path to the metadata CSV file, `folder` the name of the images folder and `n` sample size. See below for how the function is used to get `x_boys_train` and `x_girls_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TjdsdI_5HEtQ"
   },
   "outputs": [],
   "source": [
    "def get_images_matrix(csv_file, folder, n = None, seed = 1976):\n",
    "    df =  ### YOUR CODE HERE ###\n",
    "    files_list =  ### YOUR CODE HERE ###\n",
    "    images =  ### YOUR CODE HERE ###\n",
    "    return images, files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YyprS8qOHEtT"
   },
   "outputs": [],
   "source": [
    "folder = 'ebay_boys_girls_shirts/'\n",
    "x_boys_train, boys_files_list = get_images_matrix(folder + 'boys_train.csv', folder + 'boys', 2000)\n",
    "x_girls_train, girls_files_list = get_images_matrix(folder + 'girls_train.csv', folder + 'girls', 2000)\n",
    "\n",
    "print(x_boys_train.shape)\n",
    "print(x_girls_train.shape)\n",
    "print(*boys_files_list[:5], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSDxDGhl6-z_"
   },
   "source": [
    "Loading the images might take several minutes, please be patient (probably it will take a bit more time for the google colab users).\n",
    "\n",
    "For sanity check, make sure that the first 5 elements at boys_files_list are as follows:\n",
    "\n",
    "\n",
    "```\n",
    "['ebay_boys_girls_shirts/boys/7997.jpg',\n",
    " 'ebay_boys_girls_shirts/boys/14031.jpg',\n",
    " 'ebay_boys_girls_shirts/boys/15402.jpg',\n",
    " 'ebay_boys_girls_shirts/boys/1671.jpg',\n",
    " 'ebay_boys_girls_shirts/boys/9077.jpg']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_e7lJHOHEtX"
   },
   "source": [
    "Can you calculate the size of each of our 4D numpy arrays? Verify with this helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWWG6NMGHEtX"
   },
   "outputs": [],
   "source": [
    "def numpy_array_size_in_bytes(a):\n",
    "    print(a.size * a.itemsize)\n",
    "\n",
    "numpy_array_size_in_bytes(x_boys_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYh_z1_VHEta"
   },
   "source": [
    "But we can't use our 4D arrays with PCA just yet. We need to:\n",
    "\n",
    "(a) Reshape them as 2D arrays having N rows (images) X P columns (pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NnJ6EybeHEtb"
   },
   "outputs": [],
   "source": [
    "def get_all_pixels(x):\n",
    "    return x.reshape(-1, np.prod(x.shape[1:]))\n",
    "\n",
    "x_boys_train_all = get_all_pixels(x_boys_train)\n",
    "x_girls_train_all = get_all_pixels(x_girls_train)\n",
    "\n",
    "print(x_boys_train_all.shape)\n",
    "print(x_girls_train_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5hcocIfHEte"
   },
   "source": [
    "(b) Stack them one on top of the other, to have a giant `x_train` 2D numpy array, of size [4000, 30000].\n",
    "\n",
    "Do that. Remember the docs, SO and good old Google (though once you get experience you're expected to know this yourself!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xcpuhEo3HEtf"
   },
   "outputs": [],
   "source": [
    "x_train = ### YOUR CODE HERE ###\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30UD_-_THEti"
   },
   "source": [
    "As in class, we first center the `x_train` matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DzPsb5L7HEti"
   },
   "outputs": [],
   "source": [
    "x_train_centered = x_train - x_train.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mt0HlgLAHEtm"
   },
   "source": [
    "Can you calculate the `x_train_centered` matrix size in bytes? Use the `numpy_array_size_in_bytes` function to help you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rgfe44FHEtn"
   },
   "outputs": [],
   "source": [
    "numpy_array_size_in_bytes(x_train_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LbWlz64NHEtq"
   },
   "source": [
    "Does this result surprise you? Make sure you get this calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JrpO2GQlHEtr"
   },
   "source": [
    "How would you show that `x_train_centered` is indeed centered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRnFcn6NHEts"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yxSdJTm0HEtv"
   },
   "source": [
    "As in class, we import `PCA` from [sklearn](https://scikit-learn.org/stable/) and fit it to data, asking for say first 10 PCs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_Vj_jz8HEtw"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 10)\n",
    "\n",
    "pca.fit(x_train_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUSMKrl4HEty"
   },
   "source": [
    "How would you get the `W` matrix of weights? (see class or the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y52yYM34HEtz"
   },
   "outputs": [],
   "source": [
    "W = ### YOUR CODE HERE ###\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_o7dygWHEt2"
   },
   "source": [
    "We multiply `x_train_centered` by `W` to get the reduced `x_train_reduced`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lk3iQwU7HEt2"
   },
   "outputs": [],
   "source": [
    "x_train_reduced = np.matmul(x_train_centered, W.T)\n",
    "\n",
    "print(x_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DjZ06y6gHEt5"
   },
   "source": [
    "What's the \"sklearn\" way of performing the last two stages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GHUHMRQHEt6"
   },
   "outputs": [],
   "source": [
    "x_train_reduced = ### YOUR CODE HERE ###\n",
    "\n",
    "print(x_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBXQ4yOZHEt9"
   },
   "source": [
    "Let's compare boys and girls shirts images distribution of score on the first PC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Go1CeTE5HEt9"
   },
   "outputs": [],
   "source": [
    "plt.hist(x_train_reduced[:2000, 0], alpha=0.5, label='boys', color = 'blue')\n",
    "plt.hist(x_train_reduced[2000:, 0], alpha=0.5, label='girls', color = 'pink')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CqjLJ1frHEuA"
   },
   "source": [
    "There doesn't seem to be a dramatic effect as we might have wanted, for better classification later on. Try this with other PCs, in our experience the 2nd PC captures \"boys-like\" vs. \"girls-like\" differences better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRm2mEnAHEuB"
   },
   "source": [
    "Plot the images as points in a scatterplot (`plt.scatter`) of their score in the first PC vs. their score in the second PC. Use different colors for boys shirts images and for girls shirts images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1raTNXbHEuB"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0cy7VNjHEuE"
   },
   "source": [
    "Since we're dealing with images the best way to get what a given PC's \"subject\", what it is \"talking about\" is to simply to view those images which have a high or low score for this PC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "148JIhMmHEuE"
   },
   "source": [
    "Which 16 images have the highest score for PC1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yvGfbUTGHEuF"
   },
   "outputs": [],
   "source": [
    "highest_score_ids = np.argpartition(x_train_reduced[:, 0], -16)[-16:]\n",
    "print(highest_score_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfhkp6svHEuH"
   },
   "source": [
    "Which 16 images have the lowest score for PC1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PJrS0XKeHEuI"
   },
   "outputs": [],
   "source": [
    "lowest_score_ids = np.argpartition(x_train_reduced[:, 0], 16)[:16]\n",
    "print(lowest_score_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5o7oz2QHEuL"
   },
   "source": [
    "We got the indices of the highest and lowest shirts images for PC1. How do we connect them back to the actual files so we can show them? If you recall when we sampled the images we also got the `boys_files_list` and `girls_files_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWxkTn7CHEuM"
   },
   "outputs": [],
   "source": [
    "all_files_list = np.array(boys_files_list + girls_files_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BStpUoCnHEuO"
   },
   "source": [
    "So the highest and lowest score files are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WphyCS0tHEuO"
   },
   "outputs": [],
   "source": [
    "highest_score_files = all_files_list[highest_score_ids]\n",
    "lowest_score_files = all_files_list[lowest_score_ids]\n",
    "\n",
    "highest_score_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3CeERnRrHEuR"
   },
   "source": [
    "And now we can use our `read_images_4d_array` and `merge_images` functions from CSD2 to read these images and present them on a grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTaMkGCbHEuS"
   },
   "outputs": [],
   "source": [
    "def merge_images(image_batch, size = [20, 20]):\n",
    "    h,w = image_batch.shape[1], image_batch.shape[2]\n",
    "    c = image_batch.shape[3]\n",
    "    img = np.zeros((int(h*size[0]), w*size[1], c))\n",
    "    for idx, im in enumerate(image_batch):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w,:] = im/255\n",
    "    return img\n",
    "\n",
    "highest_images = read_images_4d_array(highest_score_files)\n",
    "lowest_images = read_images_4d_array(lowest_score_files)\n",
    "\n",
    "highest_images_merged = merge_images(highest_images, size = [4, 4])\n",
    "lowest_images_merged = merge_images(lowest_images, size = [4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40kngJIEHEuU"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Highest PC1 Score Shirts')\n",
    "plt.axis('off')\n",
    "plt.imshow(highest_images_merged)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Lowest PC1 Score Shirts')\n",
    "plt.axis('off')\n",
    "plt.imshow(lowest_images_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G_tD695nHEuW"
   },
   "source": [
    "Well now it is quite clear what PC1 is all about..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "grEdRSStHEuX"
   },
   "source": [
    "Combine all of the above to a function called `plot_highest_lowest_on_PC` which would accept a PC number (0 to 9) and plot a 4x4 grid of the 16 shirts images with highest and lowest scores on this PC, side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RDc5-qYHHEuY"
   },
   "outputs": [],
   "source": [
    "def plot_highest_lowest_on_PC(pc):\n",
    "    ### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aa2FiqmsHEua"
   },
   "outputs": [],
   "source": [
    "plot_highest_lowest_on_PC(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpPLtgqfHEuc"
   },
   "source": [
    "### And now for some questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VFczNPU2VthM"
   },
   "source": [
    "### Q11.\n",
    "\n",
    "What is the **total** explained variance ratio of the first 3 components of the pca?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "euteFhw0VthM"
   },
   "outputs": [],
   "source": [
    "ans['Q11'] = np.round(#### your code here ####,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xE-qW02BVthP"
   },
   "source": [
    "#### please answer the questions below with one number, as an integer. please make sure that you don't write anything else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYckyvGeHEug"
   },
   "source": [
    "### Q12.\n",
    "\n",
    "What is the dominant color for shirts with high PC1 (number 0) score?<br>\n",
    "    \n",
    "    1- white\n",
    "\n",
    "    2- black\n",
    "\n",
    "    3- blue\n",
    "\n",
    "    4- red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWWiiMg_VthR"
   },
   "outputs": [],
   "source": [
    "ans['Q12'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9pkVlXvVthT"
   },
   "source": [
    "### Q13.\n",
    "\n",
    "What is the dominant color for shirts with low PC1 (number 0) score?<br>\n",
    "\n",
    "    1- white\n",
    "\n",
    "    2- black\n",
    "\n",
    "    3- blue\n",
    "\n",
    "    4- red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RhClFWyiVthT"
   },
   "outputs": [],
   "source": [
    "ans['Q13'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O5Fo66GTVthV"
   },
   "source": [
    "### Q14.\n",
    "\n",
    "What is the dominant color for shirts with high PC3 (number 2) score?\n",
    "\n",
    "    1- white\n",
    "\n",
    "    2- black\n",
    "\n",
    "    3- blue\n",
    "\n",
    "    4- red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCo3hna5VthV"
   },
   "outputs": [],
   "source": [
    "ans['Q14'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPWQypp9VthY"
   },
   "source": [
    "### Q15.\n",
    "\n",
    "What is the dominant color for shirts with low PC3 (number 2) score?\n",
    "\n",
    "    1- white\n",
    "\n",
    "    2- black\n",
    "\n",
    "    3- blue\n",
    "\n",
    "    4- red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-Bt_5WsVthY"
   },
   "outputs": [],
   "source": [
    "ans['Q15'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJTEYy2hCpUi"
   },
   "source": [
    "# Finish!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3krdd3wwimf"
   },
   "source": [
    "* To submit your HW please run this last code block and follow the instructions.\n",
    "* This code will create a CSV file in the current directory on your local machine or in your google drive (Google Colab)\n",
    "* Please download it and upload it to the moodle HW1\n",
    "* Make sure that you write your ID correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ans = pd.DataFrame.from_dict(ans, orient='index')\n",
    "if df_ans.shape[0] == 18:\n",
    "  df_ans.to_csv('{}_{}.csv'.format(ans['HW'],str(ans['id_number'])))\n",
    "else:\n",
    "    print(\"seems like you missed a question, make sure you have run all the code blocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Google Colab users who want to save their CSV in their drive**\n",
    "\n",
    "* Run the following script.\n",
    "* Note that you will need to authorize GD once. For more information: https://colab.research.google.com/notebooks/io.ipynb (under Mounting Google Drive locally)\n",
    "* You may change the path to be in your inner folder at GD, or not use GD at all and just manually download the CSV file to your local machine.\n",
    "* Eventually upload the CSV to Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Three options of the path of the file \n",
    "path ='/content/drive/MyDrive/' # general outer folder\n",
    "# path = '/content/drive/MyDrive/Colab Notebooks/Intro_DS_2023/HW/HW3/' # assuming an inner folder called Intro_DS_2023 etc.\n",
    "# path = './' # here, in this notebook environment\n",
    "\n",
    "import pandas as pd \n",
    "df_ans = pd.DataFrame.from_dict(ans, orient='index')\n",
    "\n",
    "if df_ans.shape[0] == 18:\n",
    "  df_ans.to_csv(path+'{}_{}.csv'.format(ans['HW'],str(ans['id_number'])))\n",
    "else:\n",
    "    print(\"seems like you missed a question, make sure you have run all the code blocks\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
