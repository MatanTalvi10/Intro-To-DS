{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlK2M0CRbmrb"
   },
   "source": [
    "# HW 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfCMNRQdbmrd"
   },
   "source": [
    "## Instructions\n",
    "\n",
    "* The course will be using an automatic grading system.\n",
    "* After each question there will appear a code block with some prepared code to add your answer to a dictionary that will be converted into a data frame, saved as CSV and uploaded to moodle for grading.\n",
    "* Please do not edit any code other than in placeholders marked `#### your code here ####`, **notice the answer could also be a simple number or string, not an actual code**\n",
    "* Don't forget to run the code block after you write your answer.\n",
    "* You can add code blocks wherever you want in order to interact with datasets and play with your own code.\n",
    "* In the next code block please fill in your ID number and email account as strings in the appropriate places.\n",
    "* And don't forget to run the block!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shmbfA9ibmre"
   },
   "outputs": [],
   "source": [
    "ans = {}\n",
    "ans['HW'] = 'HW3'\n",
    "ans['id_number'] = #### your code here ####\n",
    "ans['email'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mora Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2MN9pRamZFw"
   },
   "source": [
    "### Q1.\n",
    "Behold the `fifa_wide` DF. There's only so much we can do with it in current form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZcXOQi2i7ke"
   },
   "outputs": [],
   "source": [
    "fifa_d = {'Country': ['France', 'Germany', 'Spain', 'Argentina', 'Brazil'],\n",
    "      'Continent': ['Europe', 'Europe', 'Europe', 'South America', 'South America'],\n",
    "      '2014': [7, 1, 23, 2, 4],\n",
    "      '2018': [1, 22, 10, 16, 6],\n",
    "      '2022': [2, 17, 13, 1, 7]}\n",
    "\n",
    "fifa_wide = pd.DataFrame(fifa_d)\n",
    "fifa_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89fyduYPmkO8"
   },
   "source": [
    "Which of the following Pandas methods would be **most easy** to make `fifa_wide` into `fifa_long`, a table with 4 columns (say `[Country, Continent, Year, Rank]`) and 15 rows, holding for each country, for each World Cup year, its Rank.\n",
    "\n",
    "1. `pd.pivot()`\n",
    "2. `pd.get_dummies()`\n",
    "3. `pd.melt()`\n",
    "4. `pd.merge()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMUaDJn4oq5Z"
   },
   "outputs": [],
   "source": [
    "ans['Q1'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bME6d1ZfbmsI"
   },
   "source": [
    "We have downloaded from [Gapminder data repository](https://www.gapminder.org/data/) the life expectancy data for all countries in the years 1900-1999. \n",
    "\n",
    "* Upload the `life_expectancy_years.csv` file from Moodle, however you want.\n",
    "* Extract from this dataset countries that have data for all years in the range 1900-1999 (i.e. you should discard countires with `Nan` values in years 1900-1999).\n",
    "* You should get 184 countries.\n",
    "* Create for each of these the average age for each decade (1900-1909, 1910-1919,...), resulting with a matrix of 184 countries (rows) times 10 decades averages (the country's name is an extra column, so 11 columns).\n",
    "\n",
    "\n",
    "**Important:** There are many ways to do this manipulation. Looping isn't a sin, but you should know where to use it.\n",
    "\n",
    "**Sanity check:** the maximum value at the 90s (1990-1999) should be about `80.11`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qh4Yxv2LbmsL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_pop = pd.read_csv('life_expectancy_years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here (no credit)###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S14x7ZhV3Oke"
   },
   "source": [
    "### Q2.\n",
    "Which country had the highest life expectancy in the 1970s (1970-1979) ? \n",
    "\n",
    "1. Japan\n",
    "2. Greece\n",
    "3. Switzerland\n",
    "4. Norway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcHgPtDC3NNv"
   },
   "outputs": [],
   "source": [
    "ans['Q2'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mb8TT4h6bmsh"
   },
   "source": [
    "### Q3.\n",
    "How many countries had at least 1 \"peak\" decade? A peak decade is a decade which had a higher life expectancy compared to both the deacdes before and after it (the 1900s and 1990s cannot be called that here)\n",
    "\n",
    "1. 62\n",
    "2. 72\n",
    "3. 78\n",
    "4. 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4P8PA95Lbmsi"
   },
   "outputs": [],
   "source": [
    "ans['Q3'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vlpum99Xbmsk"
   },
   "source": [
    "### Q4.\n",
    "In which decade did most countries experience a decrease in life expectancy compared to the previous decade? (see if you can think of a reason) E.g. if you check from 1980s to 1990s about 20% of countries decreased in life expectency.\n",
    "\n",
    "1. 1910s compared to 1900s\n",
    "2. 1920s compared to 1910s\n",
    "3. 1940s compared to 1930s\n",
    "4. 1950s compared to 1940s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsVa69HIbmsk"
   },
   "outputs": [],
   "source": [
    "ans['Q4'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbmxCDsybmsn"
   },
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM2rT2dGbmsn"
   },
   "source": [
    "### Q5.\n",
    "We have 101 observations for length of hospital stays, with maximum value 95 days, minimum 7 days, and average and median both 50 days. Now assume some software bug is causing the data to change from being measured in days to minutes (the length is multiplied by 24*60=1440). What is the minimal number of observations needed to change before the average exceeds 100?\n",
    "\n",
    "1. 1\n",
    "2. 5\n",
    "3. 10\n",
    "4. 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMlS04fQbmso"
   },
   "outputs": [],
   "source": [
    "ans['Q5'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ufo60Libmsr"
   },
   "source": [
    "### Q6.\n",
    "In the same setting, what is the minimal number of observations needed to change before the median exceeds 100? \n",
    "\n",
    "1. 1\n",
    "2. 10\n",
    "3. 51\n",
    "4. 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JZnMldrbmss"
   },
   "outputs": [],
   "source": [
    "ans['Q6'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Yy9J_0sbmsv"
   },
   "source": [
    "### Q7.\n",
    "Assume the pollution in city A is exactly double that in city B every day. We measure the pollution in city A over 100 days and put it in a vector $x=(x_1, \\dots, x_{100})$ and in city B over the same 100 days giving $y=(y_1, \\dots, y_{100})$. We also consider the vectors $u=(log(x_1), \\dots ,log(x_{100}))$ and $v = (log(y_1), \\dots ,log(y_{100}))$. Which of the following holds: \n",
    "\n",
    "1. $u_{10}$ (the 10th observation in $u$) is double $v_{10}$ \n",
    "2. The dispersion of $x$ is bigger than of $y$, but the dispersion of $u$ is equal to that of $v$\n",
    "3. If $x_{10}$ > $y_{10}$ then $u_{10} < v_{10}$\n",
    "4. None of the above \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcksOjxVbmsy"
   },
   "outputs": [],
   "source": [
    "ans['Q7'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-clkiAHXbmrp"
   },
   "source": [
    "## Basic Scraping\n",
    "\n",
    "Consider the following html snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " html_doc = \"\"\"\n",
    "\n",
    "    <html><head><title>The Dormouse's story</title></head>\n",
    "    <body>\n",
    "    <p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "    <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "    <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "    <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "    <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "    and they lived at the bottom of a well.</p>\n",
    "\n",
    "    <p class=\"story\">Here is an image of Elsie: <a href=\"http://example.com/elsie\"><img src = \"elsie.png\"></a></p>\n",
    "    <p class=\"story\">And here is an image of Lacie: <a href=\"http://example.com/lacie\"><img src = \"lacie.png\"></a></p>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCscyaDHbmrt"
   },
   "source": [
    "### Q8.\n",
    "We would like to get a list of the three little sisters names. Fill in the missing line of the following function:\n",
    "\n",
    "```python    \n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    soup = BeautifulSoup(html_doc)\n",
    "\n",
    "    def get_sisters_names(soup):\n",
    "        # missing line 1 #\n",
    "        return [sister.get_text() for sister in sisters]\n",
    "```\n",
    "\n",
    "1. `sisters = soup.find_all('sister')`\n",
    "2. `sisters = soup.find_all('a')`\n",
    "3. `sisters = soup.find_all(class = 'sister')`\n",
    "4. `sisters = soup.find_all('a', {'class': 'sister'})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7j9aAPKZbmrw"
   },
   "outputs": [],
   "source": [
    "ans['Q8'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAO904D0bmry"
   },
   "source": [
    "### Q9.\n",
    "Now we would like to get only the raw text of the Dormouse story, not including the title. Fill in the missing lines of the following function:\n",
    "\n",
    "```python    \n",
    "    def get_story(soup):\n",
    "        # missing line 1 #\n",
    "        story = ''\n",
    "        for p in paragraphs:\n",
    "            # missing line 2 #\n",
    "            if class_name == 'story':\n",
    "                story += p.get_text() + ' '\n",
    "        return ' '.join(story.split())\n",
    "```\n",
    "\n",
    "1. line 1: `paragraphs = soup.find_all('p', {'class': 'story'})`; line 2: `class_name = p['class']`\n",
    "2. line 1: `paragraphs = soup.find_all('p')`; line 2: `class_name = p['class'][0]`\n",
    "3. line 1: `paragraphs = soup.find_all('p', {'class': 'story'})`; line 2: `class_name = p.find('class')[0]`\n",
    "4. line 1: `paragraphs = soup.find_all('story')`; line 2: `class_name = p.attr['class']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVd9MEu-bmr1"
   },
   "outputs": [],
   "source": [
    "ans['Q9'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPY0lOYXbmr4"
   },
   "source": [
    "### Q10.\n",
    "What will be the result of calling the following function on our `soup` object (i.e. `does_something(soup)`)?\n",
    "\n",
    "```python    \n",
    "    def does_something(soup):\n",
    "        return [e['src'].split('.')[0] for e in soup.find_all('img')]\n",
    "```\n",
    "\n",
    "1. `['elsie.png', 'lacie.png']`\n",
    "2. `['elsie', 'lacie']`\n",
    "3. `{'src': ['elsie', 'lacie']}`\n",
    "4. The function will throw an exception on our `soup` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iudzc7Llbmr9"
   },
   "outputs": [],
   "source": [
    "ans['Q10'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping ebay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [ebay.com](ebay.com) and search for little boys t-shirts. The ebay website, like any modern website, is filled with text, images and links. But if you are using Google Chrome and you right-click on any page and choose \"View page source\" you will see the raw HTML script behind it.\n",
    "\n",
    "Run the following piece of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://il.ebay.com/b/Boys-Short-Sleeve-Sleeve-Tops-T-Shirts-Sizes-4-Up/175521/bn_4278610?rt=nc&LH_ItemCondition=1000&LH_BIN=1&LH_PrefLoc=3&_pgn=1'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code imports Beautiful Soup, imports the requests library for handling web connections, assigns an ebay search results page address to a variable called `url`, \"requests\" this URL, stores the response in a variable called `r`, makes a `BeautifulSoup` object out of the response's `content`, and assigns it to a variable called `soup`.\n",
    "\n",
    "It is advised to visit the url using your browser, so you will have a visual understanding of what you are doing.\n",
    "\n",
    "Print the raw HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11.\n",
    "What is the page's title? Replace `#### your code here ####` to get the title as a simple string, without html tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_title = #### your code here ####\n",
    "print(url_title)\n",
    "ans['Q11'] = url_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the all hyperlinks on page (no credit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = #### your code here ####\n",
    "print('all_links is a: ' + str(type(all_links)))\n",
    "print()\n",
    "print('first 5 elements in all_links:')\n",
    "print(all_links[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12.\n",
    "What is the class type of `all_links`?\n",
    "\n",
    "Note: if  the type is <class 'XXXXX'> please write in the answer the correct class (e.g. 'XXXXX' as in this example) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['Q12'] = ### your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the all images on page (no credit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ### your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a `list` of all image titles from the `images` object, **except for the first one**. Print that list (no credit).\n",
    "\n",
    "Hint: `alt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_titles = ### your code here ###\n",
    "print(image_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need images JPEG addresses. Some have them as attribute `src`, some as attribute `data-src`. This is one way to combine the two. Make sure you understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files_src = [img.get('src', None) for img in images[1:]]\n",
    "image_files_datasrc = [img.get('data-src', None) for img in images[1:]]\n",
    "image_files = [src if datasrc is None else datasrc for src, datasrc in zip(image_files_src, image_files_datasrc)]\n",
    "image_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find a shirt's price.\n",
    "\n",
    "Go to the url in your browser and use the code inspection tool (F12) to look interactively at the url source code. Find the element that holds price data. Notice that the price may be nested within a few levels of html tags. you are searching for the \"lowest\" level, the one that holds the price directly.\n",
    "\n",
    "In our case it is a `span` element with a specific class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q13.\n",
    "What is the specific class for span elements holding the prices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_class = ### your code here ###\n",
    "ans['Q13'] = price_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_elements = soup.find_all('span', {'class' : price_class})\n",
    "print(price_elements[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From each of these `price_elements` we extract the actual price text with the `get_text` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(price_elements[1].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice all prices come with the \"ILS\" prefix and then the number. Also you can see some prices come as a range. For this project we decided to simply take the minimum price of the range.\n",
    "\n",
    "To do so we could split this string to its elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(float(price_elements[1].get_text().split(' ')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it in a function and getting all prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_price(price_element):\n",
    "    try:\n",
    "        price = float(price_element.get_text().split(' ')[1])\n",
    "    except:\n",
    "        price = None\n",
    "    return price\n",
    "\n",
    "prices = [parse_price(price_e) for price_e in price_elements]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to actually download the shirts images! The following function accepts an image file address, a shirt title and the file name for the image and attempts to download the image to the current directory with the specified file name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, title, file_name):\n",
    "    try:\n",
    "        response = requests.get(url)    \n",
    "    except:\n",
    "        return '', ''\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    return title, file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the first image from our page, name it 'test.jpg' (no credit). Make sure it was downloaded correctly and see what the function returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_image(### your code here ###)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now download all of the page's images, using a loop. \n",
    "\n",
    "First, create a folder named 'boys' in the current directory. You can do it right here in this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir boys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want these images in your Google Drive it needs to be mounted, and then (uncomment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd '/content/drive/MyDrive/Colab Notebooks/Intro_DS_2023/HW/HW3/' # assuming an inner folder called Intro_DS_2023 etc.\n",
    "\n",
    "# !pwd\n",
    "# !mkdir boys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q14, Q15.\n",
    "Fill in the blanks to correctly create a dictionary called `images_data` which will hold the `title` of the image, its `file_name`, and the shirt's `price`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "your_answer_1 = ### your code here ###\n",
    "your_answer_2 = ### your code here ###\n",
    "\n",
    "\n",
    "images_data = {'title': {},\n",
    "               your_answer_1: {},\n",
    "               'price': {}}\n",
    "\n",
    "f = IntProgress(min = 0, max = len(images[1:])) # instantiate a progress bar\n",
    "display(f) # display the bar\n",
    "\n",
    "for i in range(len(images[1:])):\n",
    "    title, file_name = download_image(image_files[i], image_titles[i], './boys/' + str(i) + '.jpg')\n",
    "    images_data['title'][i] = title\n",
    "    images_data['file_name'][i] = file_name\n",
    "    images_data[your_answer_2][i] = prices[i]\n",
    "    f.value += 1\n",
    "\n",
    "        \n",
    "ans['Q14'] = your_answer_1 \n",
    "ans['Q15'] = your_answer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that would prove useful later on is having a dataset which summarizes all we have gathered. That's what `images_data` is for. We're going to use `pandas` to make it a `DataFrame` we can easily read and write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "images_data_df = pd.DataFrame(images_data)\n",
    "print(images_data_df.shape)\n",
    "images_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was fun, we got 48 images. But we're looking to get times ~200 than that, and the same amount of shirts images for girls. \n",
    "\n",
    "The following function was run to get all boys shirts images. Challenge yourself to complete it exactly as we did, but don't run it, we have the images for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False # change this to actually run\n",
    "\n",
    "if run:\n",
    "    boys_url = 'https://il.ebay.com/b/Boys-Short-Sleeve-Sleeve-Tops-T-Shirts-Sizes-4-Up/175521/bn_4278610?rt=nc&LH_ItemCondition=1000&LH_BIN=1&LH_PrefLoc=3&_pgn=1'\n",
    "    max_pages = 400\n",
    "    boys_items_data = {'title': {}, 'file_id': {}, 'price': {}}\n",
    "\n",
    "    f = IntProgress(min = 0, max = max_pages)\n",
    "    display(f)\n",
    "\n",
    "    all_items_counter = 0\n",
    "\n",
    "    for page_num in range(max_pages):\n",
    "        url = boys_url + str(page_num)\n",
    "        try:\n",
    "            r = requests.get(url, \"lxml\")\n",
    "        except:\n",
    "            print('Stopped at page: ' + page_num)\n",
    "            break\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        ### get images, image_titles, image_files, prices ###\n",
    "\n",
    "        try:\n",
    "            assert len(prices) == len(images)\n",
    "        except:\n",
    "            print('Found unequal number of prices in page_num % d' % page_num)\n",
    "            prices = [None] * len(images)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            title, file_name = download_image(### your code here ###)\n",
    "            boys_items_data['title'][all_items_counter + i] = title\n",
    "            boys_items_data['file_id'][all_items_counter + i] = all_items_counter + i\n",
    "            boys_items_data['price'][all_items_counter + i] = prices[i]\n",
    "        all_items_counter += len(images)\n",
    "        f.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic EDA on ebay images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ebay_boys_girls_shirts.tar.gz` file is about 250MB on disk. You can either:\n",
    "\n",
    "1. Store it on your local machine, read and extract it as shown below (because you're working with Jupyter Notebooks). Notice this would extract all images locally, you would not have to do this again later on.\n",
    "2. Store it on your local machine, then **if you have a super-fast internet connection** upload it manually to your Google Colab notebook environment like any other file, exrtact it there -- the upload might be very slow, so not recommended\n",
    "3. Store it on Google Drive, then ount Google Drive, copy the file to your Google Colab notebook, then extract it there -- my preferred option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run just one of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option 1\n",
    "# import tarfile\n",
    "\n",
    "# path = '../' # this is the path to my local file, what is yours?\n",
    "\n",
    "# # extract it\n",
    "# with tarfile.open(path + 'ebay_boys_girls_shirts.tar.gz') as tar:\n",
    "#     tar.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option 2\n",
    "# # (after you have uploaded the file to Google Colab notebook - really, it didn't take hours?!)\n",
    "# !tar -xzvf ebay_boys_girls_shirts.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option 3\n",
    "# # copy the file from GD\n",
    "# !cp drive/MyDrive/ebay_boys_girls_shirts.tar.gz .\n",
    "\n",
    "# # extract it\n",
    "# !tar -xzvf ebay_boys_girls_shirts.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the images, let's look at some of the images in the training set. In order to see boys vs. girls shirts, we'll display a random group from each folder, side by side.\n",
    "\n",
    "Let's get the metadata CSV files first as `pandas` DataFrames. Inspect these DF's and understand what the data in them means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = '../' # this is MY path, e.g. if the folder is in the current notebook environment, change this to '.'\n",
    "folder = path + 'ebay_boys_girls_shirts/'\n",
    "boys_train_df = pd.read_csv(folder + 'boys_train.csv')\n",
    "girls_train_df = pd.read_csv(folder + 'girls_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boys_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a random sample of 400 image files (without replacement) from each folder (boys and girls), completing the following function (no credit):\n",
    "\n",
    "`file_ids_list` should hold a random sample of size `n_sample`  from `df`. \n",
    "\n",
    "**Hint1**: Take into account the dimensions of the DataFrame\n",
    "\n",
    "**Hint2**: You might find  the function `np.random.choice()` useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(df, folder, n_sample = None, seed = None):\n",
    "  np.random.seed(0)\n",
    "  if n_sample is None:\n",
    "      file_ids_list = df.file_id.values\n",
    "  else:\n",
    "      file_ids_list = ### your code here ###\n",
    "  files_list = [folder + '/' + str(file_id) + '.jpg' for file_id in file_ids_list]\n",
    "  return files_list\n",
    "\n",
    "boys_display_files = get_file_list(boys_train_df, folder + 'boys', 400)\n",
    "girls_display_files = get_file_list(girls_train_df, folder + 'girls', 400)\n",
    "print(boys_display_files[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to read each batch of random images as a 4D `numpy` array. Why 4D? That's [N images X height X width X N color channels], where in our case `N color channels` is 3 (Red, Green and Blue).\n",
    "\n",
    "The function `read_image_and_resize()` takes an image file address `f`, reads it with the standard [matplotlib](https://matplotlib.org/) library, `resize`s it to the given width and height in pixels (we use 100 for both) with the [skimage](http://scikit-image.org/docs/dev/api/skimage.html) library, and makes sure it is a 4D array, the size of `[1, 100, 100, 3]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform, color, img_as_ubyte\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def read_image_and_resize(f, w = 100, h = 100):\n",
    "    if f.endswith('jpg'):\n",
    "      img = cv2.imread(f)\n",
    "      with warnings.catch_warnings():\n",
    "          warnings.simplefilter(\"ignore\")\n",
    "          img = transform.resize(img, (w, h), mode='constant') \n",
    "          img = img_as_ubyte(img)\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      img = img[np.newaxis, :, :, :3]\n",
    "      if img.shape != (1, 100, 100, 3):\n",
    "          raise ValueError(f + str(img.shape))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `read_images_4d_array()` function which receives for boys and for girls our list of random images files and returns the final 4D array.\n",
    "\n",
    "First create the list of single 4D arrays called `images_list`. Then lookup [NumPy](http://www.numpy.org/) documentation (or wherever you want) to see the proper NumPy function to \"glue\" the list of arrays into a single array called `images_array` (it has to be a 4D array).\n",
    "\n",
    "**Hint**: there are several ways to do it, `np.squeeze()` is one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_4d_array(files_list):\n",
    "    images_list = #[### your code here ### for file in files_list]\n",
    "    images_array = ### your code here ###\n",
    "    return images_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16, Q17.\n",
    "Your final arrays for boys and for girls should be of dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boys_display_images = read_images_4d_array(boys_display_files)\n",
    "girls_display_images = read_images_4d_array(girls_display_files)\n",
    "print(boys_display_images.shape)\n",
    "ans['Q16'] = boys_display_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boys_display_images.dtype)\n",
    "ans['Q17'] = boys_display_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `merge_images()` will take our 4D images numpy array of 400 images and make it a 20x20 grid of sub-images. Complete the code to display two grids of boys and girls shirts side by side, as you see below (no credit):\n",
    "\n",
    "**Hint**: `plt.imshow()` might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_images(image_batch, size = [20, 20]):\n",
    "    h,w = image_batch.shape[1], image_batch.shape[2]\n",
    "    c = image_batch.shape[3]\n",
    "    img = np.zeros((int(h*size[0]), w*size[1], c))\n",
    "    for idx, im in enumerate(image_batch):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w,:] = im/255.0 #notice we divide by 255 to get 0-1 float range\n",
    "    return img\n",
    "\n",
    "boys_merged = ### YOUR CODE HERE ###\n",
    "girls_merged = ### YOUR CODE HERE ###\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 2, figsize = (20,5))\n",
    "\n",
    "ax[0].set_title('Boys Shirts')\n",
    "ax[0].axis('off')\n",
    "_ = ax[0].### YOUR CODE HERE ###\n",
    "\n",
    "ax[1].set_title('Girls Shirts')\n",
    "ax[1].axis('off')\n",
    "_ = ax[1].### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would you say is the most obvious difference between boys and girls shirts images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the color histograms for the RGB channels for our images:\n",
    "\n",
    "You'll need to know how to flatten a N-D numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print('a 3d array:')\n",
    "print(a)\n",
    "print(\"it's shape:\")\n",
    "print(a.shape)\n",
    "print(\"the 2d matrix on the first level of the 3d array\")\n",
    "print(a[:, :, 0])\n",
    "print(\"the matrix's values flattened as a 1d array\")\n",
    "print(a[:, :, 0].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `plot_hist()` function to see all color histograms for boys and girls shirts images. See the function usage below for more hints regarding its expected input.\n",
    "\n",
    "If you prefer you may change the code to use seaborn instead of matplotlib for the histogram construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(images, channel, col):\n",
    "    vals = ### YOUR CODE HERE ###\n",
    "    plt.hist(### YOUR CODE HERE ###)\n",
    "    plt.yticks([])\n",
    "\n",
    "    \n",
    "plt.figure(figsize =(10, 5))\n",
    "plt.subplot(3, 2, 1)\n",
    "plot_hist(boys_display_images, 0, 'red')\n",
    "plt.title('Boys Shirts')\n",
    "plt.subplot(3, 2, 2)\n",
    "plot_hist(girls_display_images, 0, 'red')\n",
    "plt.title('Girls Shirts')\n",
    "plt.subplot(3, 2, 3)\n",
    "plot_hist(boys_display_images, 1, 'green')\n",
    "plt.subplot(3, 2, 4)\n",
    "plot_hist(girls_display_images, 1, 'green')\n",
    "plt.subplot(3, 2, 5)\n",
    "plot_hist(boys_display_images, 2, 'blue')\n",
    "plt.subplot(3, 2, 6)\n",
    "plot_hist(girls_display_images, 2, 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would you say is the most obvious difference between boys and girls shirts images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q18, Q19, Q20.\n",
    "\n",
    "See the channels mean and median verify your \"feelings\". Also print out the share of pixels above say 220:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(images, channel, col):\n",
    "    vals = ### YOUR CODE HERE ###\n",
    "    chan_mean = np.round(### YOUR CODE HERE ###, 3)\n",
    "    chan_median = np.round(### YOUR CODE HERE ###, 3)\n",
    "    chan_share_above_220 = np.round(### YOUR CODE HERE ###, 3)\n",
    "    print('{} mean: {}, median: {}, share above 220: {}'.format(col, str(chan_mean), str(chan_median), str(chan_share_above_220)))\n",
    "\n",
    "print('Boys:')\n",
    "summary(boys_display_images, 0, 'red')\n",
    "summary(boys_display_images, 1, 'green')\n",
    "summary(boys_display_images, 2, 'blue')\n",
    "print('Girls:')\n",
    "summary(girls_display_images, 0, 'red')\n",
    "summary(girls_display_images, 1, 'green')\n",
    "summary(girls_display_images, 2, 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the summary statistics of the red channel of Girl shirts, please fill in:\n",
    "\n",
    "#### Q18: mean\n",
    "#### Q19: median\n",
    "#### Q20:  share above 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['Q18'] = ### YOUR answer HERE ###\n",
    "ans['Q19'] = ### YOUR answer HERE ###\n",
    "ans['Q20'] = ### YOUR answer HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJTEYy2hCpUi"
   },
   "source": [
    "# Finish!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3krdd3wwimf"
   },
   "source": [
    "* To submit your HW please run this last code block and follow the instructions.\n",
    "* This code will create a CSV file in the current directory on your local machine or in your google drive (Google Colab)\n",
    "* Please download it and upload it to the moodle HW1\n",
    "* Make sure that you write your ID correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ans = pd.DataFrame.from_dict(ans, orient='index')\n",
    "if df_ans.shape[0] == 23:\n",
    "  df_ans.to_csv('{}_{}.csv'.format(ans['HW'],str(ans['id_number'])))\n",
    "else:\n",
    "    print(\"seems like you missed a question, make sure you have run all the code blocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Google Colab users who want to save their CSV in their drive**\n",
    "\n",
    "* Run the following script.\n",
    "* Note that you will need to authorize GD once. For more information: https://colab.research.google.com/notebooks/io.ipynb (under Mounting Google Drive locally)\n",
    "* You may change the path to be in your inner folder at GD, or not use GD at all and just manually download the CSV file to your local machine.\n",
    "* Eventually upload the CSV to Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Three options of the path of the file \n",
    "path ='/content/drive/MyDrive/' # general outer folder\n",
    "# path = '/content/drive/MyDrive/Colab Notebooks/Intro_DS_2023/HW/HW3/' # assuming an inner folder called Intro_DS_2023 etc.\n",
    "# path = './' # here, in this notebook environment\n",
    "\n",
    "import pandas as pd \n",
    "df_ans = pd.DataFrame.from_dict(ans, orient='index')\n",
    "\n",
    "if df_ans.shape[0] == 23:\n",
    "  df_ans.to_csv(path+'{}_{}.csv'.format(ans['HW'],str(ans['id_number'])))\n",
    "else:\n",
    "    print(\"seems like you missed a question, make sure you have run all the code blocks\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "18R0GERFl8JiNWdUpQQOSGPdfSzGUXC8z",
     "timestamp": 1585132657284
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
