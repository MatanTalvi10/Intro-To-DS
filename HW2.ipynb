{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKHgaMcjCpSw"
   },
   "source": [
    "# HW 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2clz3-bCpSz"
   },
   "source": [
    "## Instructions\n",
    "\n",
    "* The course will be using an automatic grading system.\n",
    "* After each question there will appear a code block with some prepared code to add your answer to a dictionary that will be converted into a data frame, saved as CSV and uploaded to moodle for grading.\n",
    "* Please do not edit any code other than in placeholders marked `#### your code here ####`\n",
    "* Don't forget to run the code block after you write your answer.\n",
    "* You can add code blocks wherever you want in order to interact with datasets and play with your own code.\n",
    "* In the next code block please fill in your ID number and email account as strings in the appropriate places.\n",
    "* And don't forget to run the block!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u9EaHG06CpS1"
   },
   "outputs": [],
   "source": [
    "ans = {}\n",
    "ans['HW'] = 'HW2'\n",
    "ans['id_number'] = '318903028'\n",
    "ans['email'] = 'matantalvi@mail.tau.ac.il'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H-LTpDGifGV"
   },
   "source": [
    "## Avocado Data\n",
    "\n",
    "For this assignment you will need to import two csv files which can be found in moodle: `avocade_price.csv` which contains 2015-2018 daily price for avocado across the US, and `avocado_bags.csv` which contains 2015-2018 daily no. of avocado bags sold across the US."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbIM_dc_CpTx"
   },
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbPD2t_LCpTy"
   },
   "source": [
    "* In this section we will be interacting with a real dataset.\n",
    "* This next block loads the dataset from the repository.\n",
    "* Remember you are able to add code blocks to interact with the dataset.\n",
    "* If at any point you think that you might have altered the original data, you can simply rerun this code block to load a fresh copy.\n",
    "* Please do not change the blocks that record your answer to the `ans` dictionary.\n",
    "* The pandas documentation, and specifically the list of `DataFrame` methods might be helpful, [here](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 1351,
     "status": "ok",
     "timestamp": 1671196652101,
     "user": {
      "displayName": "Giora Simchoni",
      "userId": "07886879145318559495"
     },
     "user_tz": -120
    },
    "id": "VaCob2_CCpT0",
    "outputId": "860a4159-74e5-4033-cba6-20872f52660c"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'avocado_price.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# This assumes you have avocado_fixed.csv in the notebook folder\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# If you're working with a folder in Gooogle Drive and want to read from it - \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Mount the drive, either by pressing the mount drive button or by running:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m# then, reading the csv from the relevant `path` with\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# df_avocado = pd.read_csv(path + 'avocado_fixed.csv')\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df_avocado \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mavocado_price.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAvocado prices data has \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m rows and \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m columns\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m df_avocado\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     13\u001b[0m df_avocado\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'avocado_price.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This assumes you have avocado_fixed.csv in the notebook folder\n",
    "# If you're working with a folder in Gooogle Drive and want to read from it - \n",
    "# Mount the drive, either by pressing the mount drive button or by running:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# then, reading the csv from the relevant `path` with\n",
    "# df_avocado = pd.read_csv(path + 'avocado_fixed.csv')\n",
    "\n",
    "df_avocado = pd.read_csv('avocado_price.csv')\n",
    "print('Avocado prices data has %d rows and %d columns' % df_avocado.shape)\n",
    "df_avocado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4uJ-2t1ps3m"
   },
   "source": [
    "### Q1.\n",
    "What is the median of the `year` column?\n",
    "\n",
    "1. 2015\n",
    "\n",
    "2. 2016\n",
    "\n",
    "3. 2017\n",
    "\n",
    "4. 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tQjoxQCptPX"
   },
   "outputs": [],
   "source": [
    "ans['Q1'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgYeHmIzCpT4"
   },
   "source": [
    "### Q2.\n",
    "On what date and region was the price the highest?\n",
    "\n",
    "1. PhoenixTucson - 2/5/17\n",
    "\n",
    "2. Chicago - 10/8/17\n",
    "\n",
    "3. SanFrancisco - 10/30/16\n",
    "\n",
    "4. LosAngeles 2/5/17\n",
    "\n",
    "__Hint:__ the pandas data frame method `sort_values()` can come in handy, look it up in the pandas documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgx3XQKfCpT5"
   },
   "outputs": [],
   "source": [
    "ans['Q2'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.\n",
    "How many days are there in the data for the `SanFrancisco` region, in the year 2018?\n",
    "\n",
    "1. 5\n",
    "2. 12\n",
    "3. 13\n",
    "4. 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['Q3'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90D109gCCpT-"
   },
   "source": [
    "### Q4.\n",
    "Which region had the lowest price for the entire period? (on average)\n",
    "\n",
    "1. Albany\n",
    "\n",
    "2. HartfordSpringfield\n",
    "\n",
    "3. Houston\n",
    "\n",
    "4. PhoenixTucson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gN6l_w-_pIlg"
   },
   "source": [
    "__Hint:__ `groupby` and `agg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2Gsb4RJCpUA"
   },
   "outputs": [],
   "source": [
    "ans['Q4'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMYSpEetCpUD"
   },
   "source": [
    "### Q5.\n",
    "In what year were avocado prices the lowest? (on average)\n",
    "\n",
    "1. 2015\n",
    "\n",
    "2. 2016\n",
    "\n",
    "3. 2017\n",
    "\n",
    "4. 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grEkpIDiCpUE"
   },
   "outputs": [],
   "source": [
    "ans['Q5'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8NXhMzHCpUH"
   },
   "source": [
    "### Q6.\n",
    "In what year were the prices lowest in Indianapolis? (on average)\n",
    "\n",
    "1. 2015\n",
    "\n",
    "2. 2016\n",
    "\n",
    "3. 2017\n",
    "\n",
    "4. 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wf1uZsvhCpUI"
   },
   "outputs": [],
   "source": [
    "ans['Q6'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ppIpuoutZtv"
   },
   "source": [
    "### Q7.\n",
    "What is the median price in the Columbus region in 2017?\n",
    "\n",
    "1. 1.015\n",
    "\n",
    "2. 1.030\n",
    "\n",
    "3. 1.100\n",
    "\n",
    "4. 1.163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLje56lMupTA"
   },
   "outputs": [],
   "source": [
    "ans['Q7'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZo1X7JvCpUM"
   },
   "source": [
    "---\n",
    "\n",
    "We will now load some additional data to play with. The new data set holds number of avocado bags sold in each region for the same period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1671197257069,
     "user": {
      "displayName": "Giora Simchoni",
      "userId": "07886879145318559495"
     },
     "user_tz": -120
    },
    "id": "-aDTL74KsKEG",
    "outputId": "c6d5b264-7f86-47b9-b0ef-a793d511ae7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c63acb2e-496c-4a06-bdb8-8bcbaeb43f3a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>num_bags</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/27/15</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/20/15</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/13/15</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/6/15</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/29/15</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c63acb2e-496c-4a06-bdb8-8bcbaeb43f3a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c63acb2e-496c-4a06-bdb8-8bcbaeb43f3a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c63acb2e-496c-4a06-bdb8-8bcbaeb43f3a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       Date  num_bags  year  region\n",
       "0  12/27/15   8696.87  2015  Albany\n",
       "1  12/20/15   9505.56  2015  Albany\n",
       "2  12/13/15   8145.35  2015  Albany\n",
       "3   12/6/15   5811.16  2015  Albany\n",
       "4  11/29/15   6183.95  2015  Albany"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Do whatever you have to do to get that file from Moodle ###\n",
    "\n",
    "df_avocado_bags = pd.read_csv('avocado_bags.csv')\n",
    "print('Avocado bags data has %d rows and %d columns' % df_avocado_bags.shape)\n",
    "df_avocado_bags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZuoIf-GCCpUQ"
   },
   "source": [
    "__Notice:__\n",
    "* To answer the following questions you will need to join the two datasets together properly and make calculations on columns from both `DataFrame`s.\n",
    "* Assume \"avocado market\" for a single date can be measured by price times number of bags (not a trick question).\n",
    "* Note each region has only one observation on each date, and we don't have missing values - so there are no weird/spooky/shady things hiding in the data. Yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDDqzRrBCpUQ"
   },
   "source": [
    "### Q8.\n",
    "Which **of the following** regions has a larger avocado market? (in total, over the entire period)\n",
    "\n",
    "1. California\n",
    "\n",
    "2. NewYork\n",
    "\n",
    "3. Chicago\n",
    "\n",
    "4. LosAngeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUsrTqqACpUR"
   },
   "outputs": [],
   "source": [
    "ans['Q8'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwGOWaMHCpUU"
   },
   "source": [
    "### Q9.\n",
    "What year were avocado sales the highest? (in total, by avocado market, ignore that maybe data is missing for some years)\n",
    "\n",
    "1. 2015\n",
    "\n",
    "2. 2016\n",
    "\n",
    "3. 2017\n",
    "\n",
    "4. 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjXLGzEBCpUV"
   },
   "outputs": [],
   "source": [
    "ans['Q9'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10.\n",
    "How many regions have a total avocado market above `15e06` in 2016?\n",
    "\n",
    "1. 1\n",
    "2. 11\n",
    "3. 14\n",
    "4. 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['Q10'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11.\n",
    "\n",
    "All regions have the same number of days reported in the year 2017 (challenge yourself to do this with as little code as possible)\n",
    "\n",
    "1. True\n",
    "2. False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['Q11'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idik6OLHCpUX"
   },
   "source": [
    "## Data Science Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8RTgFRcCpUY"
   },
   "source": [
    "The following questions reference material from the first lecture and should be answered after the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvttmWV9CpUa"
   },
   "source": [
    "### Q12.\n",
    "Which of the following is not primarily a data science project: \n",
    "\n",
    "1.\tCollect and analyze data from a linear accelerator, looking for a new particle\n",
    "\n",
    "2.\tBuild a robot which serves cocktail drinks\n",
    "\n",
    "3.\tGiven two website designs, test which one attracts more traffic\n",
    "\n",
    "4.\tDo an online poll to predict the outcome of an election\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBFrPNFgCpUb"
   },
   "outputs": [],
   "source": [
    "ans['Q12'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCpS-IsJCpUd"
   },
   "source": [
    "We mentioned in class that data science has three interweaved components:\n",
    "* Computing expertise\n",
    "* Statistical expertise\n",
    "* Domain expertise (e.g. Physics)\n",
    "\n",
    "Consider the following tasks involved in a hypothetical data science project to find a new particle: \n",
    "\n",
    "1.\tDesigning the database to hold results\n",
    "\n",
    "2.\tDeciding which signals should be collected, and what kind of signals we are looking for to identify a new particle\n",
    "\n",
    "3.\tFitting regression models to the data and performing statistical tests in search of the signals\n",
    "\n",
    "4.  Recruiting the right personnel to carry out the project \n",
    "\n",
    "### Q13.\n",
    "Which one of the above most clearly belongs to the statistical expertise category?\n",
    "### Q14.\n",
    "Which one most clearly belongs to the computing expertise category?\n",
    "### Q15.\n",
    "Which one most clearly belongs to the domain expertise category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddf86-2BCpUf"
   },
   "outputs": [],
   "source": [
    "ans['Q13'] = #### your code here ####\n",
    "ans['Q14'] = #### your code here ####\n",
    "ans['Q15'] = #### your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exWkrREh7wMr"
   },
   "source": [
    "# Finish!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFZ4KRxx7wMs"
   },
   "source": [
    "* To submit your HW please run this last code block and follow the instructions.\n",
    "* This code will create a CSV file in the current directory on your local machine or in your google drive (Google Colab)\n",
    "* Please download it and upload it to the moodle HW1\n",
    "* Make sure that you write your ID correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ans = pd.DataFrame.from_dict(ans, orient='index')\n",
    "if df_ans.shape[0] == 18:\n",
    "  df_ans.to_csv('{}_{}.csv'.format(ans['HW'],str(ans['id_number'])))\n",
    "else:\n",
    "    print(\"seems like you missed a question, make sure you have run all the code blocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Dr21V8PdKYq"
   },
   "source": [
    "**For Google Colab users who want to save their CSV in their drive**\n",
    "\n",
    "* Run the following script.\n",
    "* Note that you will need to authorize GD once. For more information: https://colab.research.google.com/notebooks/io.ipynb (under Mounting Google Drive locally)\n",
    "* You may change the path to be in your inner folder at GD, or not use GD at all and just manually download the CSV file to your local machine.\n",
    "* Eventually upload the CSV to Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1584218897593,
     "user": {
      "displayName": "איתי מנס",
      "photoUrl": "",
      "userId": "09271931009263547573"
     },
     "user_tz": -120
    },
    "id": "ZGuDTZrsdQpS",
    "outputId": "2754df84-a16e-4cb3-970a-6acd0aaa8482"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Three options of the path of the file \n",
    "path ='/content/drive/MyDrive/' # general outer folder\n",
    "# path = '/content/drive/MyDrive/Colab Notebooks/Intro_DS_2023/HW/HW2/' # assuming an inner folder called Intro_DS_2023 etc.\n",
    "# path = './' # here, in this notebook environment\n",
    "\n",
    "import pandas as pd \n",
    "df_ans = pd.DataFrame.from_dict(ans, orient='index')\n",
    "\n",
    "if df_ans.shape[0] == 18:\n",
    "  df_ans.to_csv(path+'{}_{}.csv'.format(ans['HW'],str(ans['id_number'])))\n",
    "else:\n",
    "    print(\"seems like you missed a question, make sure you have run all the code blocks\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
